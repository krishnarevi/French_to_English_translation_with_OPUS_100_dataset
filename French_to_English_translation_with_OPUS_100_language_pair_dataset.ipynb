{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": " French to English translation with OPUS-100 language pair dataset.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/krishnarevi/TSAI_END2.0_Session7/blob/main/French_to_English_translation_with_OPUS_100_language_pair_dataset.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RQ8mZ2kNcgpn"
      },
      "source": [
        "# **French to English translation with OPUS-100 language pair dataset**\n",
        "Here we will be building a sequence to sequence deep learning model using PyTorch and TorchText to translate from French to English.Sequence to Sequence (seq2seq) model here uses an encoder-decoder architecture. Encoder neural network encodes the input sequence(french sentence) into a single vector, also called as a Context Vector,which is an abstract representation of the input sequence.This vector is then passed into the decoder neural network, which is used to output the corresponding output sequence (english translation), one word at a time."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ErwYMAvELd6a"
      },
      "source": [
        "## **Preparing Data**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x6JfrT2qX1fy"
      },
      "source": [
        "Import all the required modules."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d27S03zbAAPu"
      },
      "source": [
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchtext.legacy.data import Field, BucketIterator\n",
        "\n",
        "import spacy\n",
        "import numpy as np\n",
        "import random\n",
        "import math\n",
        "import time\n",
        "import torch, torchtext\n",
        "from torchtext import legacy\n",
        "from torchtext.legacy import data\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "from tqdm import tqdm\n",
        "from sklearn.model_selection import train_test_split\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B6mxwjlAKVhL"
      },
      "source": [
        "\n",
        "We'll set the random seeds for deterministic results."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wwu75R2jKUi_"
      },
      "source": [
        "#setting  seed\n",
        "SEED = 1234\n",
        "\n",
        "random.seed(SEED)\n",
        "np.random.seed(SEED)\n",
        "torch.manual_seed(SEED)\n",
        "torch.cuda.manual_seed(SEED)\n",
        "torch.backends.cudnn.deterministic = True"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vBdzXrGqMndz"
      },
      "source": [
        "Mount drive to access dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mbWZVM3GxXRz",
        "outputId": "cf3623eb-1885-4f20-950c-1e7b70a03697"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AYJJQcDvyRDF"
      },
      "source": [
        "path='/content/drive/MyDrive/TSAI_data/opus-100-corpus/v1.0/supervised/en-fr/'\n",
        "# %cd /content/drive/MyDrive/TSAI_data/opus-100-corpus/v1.0/supervised/en-fr"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rlYphsh9r8Az"
      },
      "source": [
        "## Dataset\n",
        "Dataset we use is from OPUS-100 corpus.It is an English-centric multilingual corpus covering 100 languages. OPUS is a growing collection of translated texts from the web.\n",
        "\n",
        "The entire corpus can be downloaded from opus-100-corpus-v1.0.tar.gz.\n",
        "Individual language pairs are also available from http://data.statmt.org/opus-100-corpus/v1.0 or from the OPUS object storage, e.g. https://object.pouta.csc.fi/OPUS-100/v1.0/opus-100-corpus-de-en-v1.0.tar.gz (replace 'de-en' with the language pair you need)\n",
        "\n",
        "OPUS-100 is English-centric, meaning that all training pairs include English on either the source or target side.The OPUS collection is comprised of multiple corpora, ranging from movie subtitles to GNOME documentation to the Bible.\n",
        "\n",
        "We will use french-english sentence pairs for our french-english neural translation model.The dataset is split into training, development, and test portions.It has been randomly sampled up to 1M sentence pairs per language pair for training and up to 2000 each for development and test. To ensure that there was no overlap (at the monolingual sentence level) between the training and development/test data, filter was applied by creators during sampling to exclude sentences that had already been sampled.\n",
        "\n",
        "Due to memory constraints in colab , we will be taking only train file (of 1M sentence pairs) and splitting into train and test sets in 70:30 ratio.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mmT_Y37nWLrY"
      },
      "source": [
        "# !wget -O en-fr.txt.zip https://object.pouta.csc.fi/OPUS-100/v1.0/opus-100-corpus-en-fr-v1.0.zip\n",
        "# !unzip en-fr.txt.zip\n",
        "# !rm en-fr.txt.zip\n",
        "# !rm OpenSubtitles.en-ru.ids"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vKPa3lkqY0oJ"
      },
      "source": [
        "Let's view first view rows of file with English sequences"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yQgdQsBXpMla",
        "outputId": "c47516a0-7986-4859-a096-13d741ee8674"
      },
      "source": [
        "!head -10 /content/drive/MyDrive/TSAI_data/opus-100-corpus/v1.0/supervised/en-fr/opus.en-fr-train.en"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The time now is 05:08 .\n",
            "This Regulation shall enter into force on the seventh day following its publication in the Official Journal of the European Union.\n",
            "Hello, what's that?\n",
            "And then I will teach you everything i know.\n",
            "Did you find something?\n",
            "Article 6\n",
            "Oh, honey, it's not your fault.\n",
            "I'm onto him now.\n",
            "DG XVI's Internet site (electronic address: http://www.cec.lu/en/comm/dg16/dg16home.html) now contains detailed information in English on pilot projects on innovation, the Information society, new sources of employment and cultural cooperation; the application forms for these innovatory measures can be downloaded in all languages of the European Union.\n",
            "Here it is.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XC0FJnj-Y_L2"
      },
      "source": [
        "Let's view first view rows of file with French sequences"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TzW1taCxpKTJ",
        "outputId": "06720824-1439-4004-9cce-c63417ff292b"
      },
      "source": [
        "!head -10 /content/drive/MyDrive/TSAI_data/opus-100-corpus/v1.0/supervised/en-fr/opus.en-fr-train.fr"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The time now is 05:05 .\n",
            "Le présent règlement entre en vigueur le septième jour suivant celui de sa publication au Journal officiel de l'Union européenne.\n",
            "Qu'est-ce que c'est que ça ?\n",
            "Et alors, je t'apprendrai tout ce que je sais.\n",
            "Par ici !\n",
            "Article 6\n",
            "- Tu n'es pas responsable.\n",
            "Je le tiens.\n",
            "Par ailleurs, le site Internet de la DG XVI (adresse électronique: http://www.cec.lu/en/comm/dg16/dg16home.html) contient désormais une information détaillée en anglais sur les projets pilotes relatifs à la promotion de l'innovation, à la société de l'information, aux nouveaux gisements d'emploi et à la coopération culturelle; et il permet de décharger les formulaires d'inscription pour ces actions novatrices dans toutes les langues de l'Union européenne.\n",
            "Le voilà.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NebRL2OKZB_e"
      },
      "source": [
        "Create train and test dataframes processing text files"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CFKytkqqynQb"
      },
      "source": [
        "def create_dataset(path,fr_data,en_data,total_lines):\n",
        "  fr_file = open(path+fr_data, 'r')\n",
        "  en_file = open(path+en_data, 'r')\n",
        "\n",
        "  dataset = {'en': [],'fr': []}\n",
        "\n",
        "\n",
        "  for i in tqdm(range(total_lines), total=total_lines):\n",
        "      fr_text = fr_file.readline()\n",
        "      en_text = en_file.readline()\n",
        "\n",
        "      if not en_text and not fr_text:\n",
        "          # one of file is finished\n",
        "          break\n",
        "\n",
        "      fr_text = fr_text.strip()\n",
        "      en_text = en_text.strip()\n",
        "      if not en_text or not fr_text:\n",
        "          continue\n",
        "\n",
        "      dataset['fr'].append(fr_text)\n",
        "      dataset['en'].append(en_text)\n",
        "  fr_file, en_file = None, None\n",
        "\n",
        "  del fr_file\n",
        "  del en_file\n",
        "\n",
        "  df = pd.DataFrame(dataset)\n",
        "  # print(df.head())\n",
        "  return df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YOobPDyWvT5j",
        "outputId": "9d6791f0-86c0-480f-c60e-caf1132a2638"
      },
      "source": [
        "df=create_dataset(path,fr_data='opus.en-fr-train.fr',en_data='opus.en-fr-train.en',total_lines=100_000)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 100000/100000 [00:00<00:00, 472356.53it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y0VnI3dSyJg_"
      },
      "source": [
        "Now we will restrict maximum sentence length to 10 due to GPU memory issue"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zWioe-UaoVFe"
      },
      "source": [
        "MAX_LENGTH=10\n",
        "def process_data(en,fr):\n",
        "\n",
        "   sentence1, sentence2 = list(en),list(fr)\n",
        "\n",
        "   pairs = []\n",
        "   for i in range(len(en)):\n",
        "       if len(sentence1[i].split(' ')) < MAX_LENGTH and len(sentence2[i].split(' ')) < MAX_LENGTH:\n",
        "           full = (sentence1[i], sentence2[i])\n",
        "           pairs.append(full)\n",
        "\n",
        "   return pairs\n",
        "\n",
        "   "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GVv0zFiDpEmz"
      },
      "source": [
        "processed_data = pd.DataFrame(process_data(df.en,df.fr), columns =['en', 'fr'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        },
        "id": "hZjB9X6Pu1os",
        "outputId": "479bbba5-4481-469d-e2b8-d24d08318c9c"
      },
      "source": [
        "processed_data.tail()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>en</th>\n",
              "      <th>fr</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>47208</th>\n",
              "      <td>Yeah, so?</td>\n",
              "      <td>Et alors ?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>47209</th>\n",
              "      <td>Carmen!</td>\n",
              "      <td>Carmen !</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>47210</th>\n",
              "      <td>- Why are you such an idiot.</td>\n",
              "      <td>- Quel crétin.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>47211</th>\n",
              "      <td>As a kid you're taught that queers are funny.</td>\n",
              "      <td>On vous dit que les homos sont bizarres.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>47212</th>\n",
              "      <td>sexy redhead (2)</td>\n",
              "      <td>sexy redhead (2)</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                  en                                        fr\n",
              "47208                                      Yeah, so?                                Et alors ?\n",
              "47209                                        Carmen!                                  Carmen !\n",
              "47210                   - Why are you such an idiot.                            - Quel crétin.\n",
              "47211  As a kid you're taught that queers are funny.  On vous dit que les homos sont bizarres.\n",
              "47212                               sexy redhead (2)                          sexy redhead (2)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 207
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "reTy5xYrRlFc"
      },
      "source": [
        "Let's check if any nan rows are there"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6Pxnet5LRyuA",
        "outputId": "37ba46c2-cff2-49d3-b27e-e433353a0bb0"
      },
      "source": [
        "print(f'sum of nan rows of train set {df.isnull().sum()}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "sum of nan rows of train set en    0\n",
            "fr    0\n",
            "dtype: int64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4bVRx4aG9cG7"
      },
      "source": [
        "(df_train, df_test) = train_test_split(processed_data, test_size=0.3, random_state=random.seed(SEED))\n",
        "assert len(df_train) + len(df_test) == len(processed_data)\n",
        "df_train=df_train.reset_index(drop=True)\n",
        "df_test=df_test.reset_index(drop=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 229
        },
        "id": "1Xfo337NANDg",
        "outputId": "a1a179b8-3658-42db-edf3-33ec7b57dc9a"
      },
      "source": [
        "print(f'Length of train  dataset \\n{len(df_train)}')\n",
        "df_train.tail()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Length of train  dataset \n",
            "33049\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>en</th>\n",
              "      <th>fr</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>33044</th>\n",
              "      <td>Mr. Walter Davis.</td>\n",
              "      <td>M. Walter Davis.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>33045</th>\n",
              "      <td>- Tell him to come in.</td>\n",
              "      <td>- Dis-lui d'entrer.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>33046</th>\n",
              "      <td>I felt like I'd done something terrible.</td>\n",
              "      <td>Comme si j'avais fait une chose horrible.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>33047</th>\n",
              "      <td>&gt; Stewardship and the convention on biological...</td>\n",
              "      <td>&gt; L'intendance et la Convention sur la diversi...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>33048</th>\n",
              "      <td>Why do people complicate their lives so, Martha?</td>\n",
              "      <td>Pourquoi les gens se compliquent-ils tant la vie?</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                      en                                                 fr\n",
              "33044                                  Mr. Walter Davis.                                   M. Walter Davis.\n",
              "33045                             - Tell him to come in.                                - Dis-lui d'entrer.\n",
              "33046           I felt like I'd done something terrible.          Comme si j'avais fait une chose horrible.\n",
              "33047  > Stewardship and the convention on biological...  > L'intendance et la Convention sur la diversi...\n",
              "33048   Why do people complicate their lives so, Martha?  Pourquoi les gens se compliquent-ils tant la vie?"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 210
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 229
        },
        "id": "C5sGTzqqxT57",
        "outputId": "8073cf10-9268-43e2-8d76-665b6dd69080"
      },
      "source": [
        "print(f'Length of test  dataset \\n{len(df_test)}')\n",
        "df_test.tail()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Length of test  dataset \n",
            "14164\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>en</th>\n",
              "      <th>fr</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>14159</th>\n",
              "      <td>Miss, look. Gem's in trouble.</td>\n",
              "      <td>Gem a des problèmes.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14160</th>\n",
              "      <td>- Word of honour? - No</td>\n",
              "      <td>- Vrai de vrai ?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14161</th>\n",
              "      <td>Listed on the Canadian Register: 2009/09/10</td>\n",
              "      <td>Inscrit au répertoire canadien: 2009/09/10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14162</th>\n",
              "      <td>Not an authorised complainant(62)</td>\n",
              "      <td>Plaignant non habilité (62)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14163</th>\n",
              "      <td>International Assistance Group, Justice Canada</td>\n",
              "      <td>International Assistance Group, Justice Canada</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                   en                                              fr\n",
              "14159                   Miss, look. Gem's in trouble.                            Gem a des problèmes.\n",
              "14160                          - Word of honour? - No                                - Vrai de vrai ?\n",
              "14161     Listed on the Canadian Register: 2009/09/10      Inscrit au répertoire canadien: 2009/09/10\n",
              "14162               Not an authorised complainant(62)                     Plaignant non habilité (62)\n",
              "14163  International Assistance Group, Justice Canada  International Assistance Group, Justice Canada"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 211
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pzaLTv_rXREs"
      },
      "source": [
        "# !pip3 install -U spacy --quiet\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gGS-Zzs2Aglb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0209aea2-468a-4913-ed6c-e8db84b2209c"
      },
      "source": [
        "%%bash\n",
        "python -m spacy download en --quiet\n",
        "python -m spacy download fr --quiet"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the model via spacy.load('en_core_web_sm')\n",
            "\u001b[38;5;2m✔ Linking successful\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/en_core_web_sm -->\n",
            "/usr/local/lib/python3.7/dist-packages/spacy/data/en\n",
            "You can now load the model via spacy.load('en')\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the model via spacy.load('fr_core_news_sm')\n",
            "\u001b[38;5;2m✔ Linking successful\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/fr_core_news_sm -->\n",
            "/usr/local/lib/python3.7/dist-packages/spacy/data/fr\n",
            "You can now load the model via spacy.load('fr')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kpoxr_kWYBBg"
      },
      "source": [
        "Load the French and English spaCy models."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vKK9oA7OArZK"
      },
      "source": [
        "spacy_fr = spacy.load('fr')\n",
        "spacy_en = spacy.load('en')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vpzMDThAYQL9"
      },
      "source": [
        "\n",
        "We create the tokenizers."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DPubajj7A0pY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c6c3c5b6-ae55-4667-b1ed-76d3928a9936"
      },
      "source": [
        "def tokenize_fr(text):\n",
        "    \"\"\"\n",
        "    Tokenizes french sequence from a string into a list of strings (tokens) and reverses it\n",
        "    \"\"\"\n",
        "    return [tok.text for tok in spacy_fr.tokenizer(text)]\n",
        "\n",
        "def tokenize_en(text):\n",
        "    \"\"\"\n",
        "    Tokenizes english sequence from a string into a list of strings (tokens)\n",
        "    \"\"\"\n",
        "    return [tok.text for tok in spacy_en.tokenizer(text)]\n",
        "### Sample Run ###\n",
        "\n",
        "sample_text = \"I love machine learning\"\n",
        "print(tokenize_en(sample_text))\n",
        "print(tokenize_fr(sample_text))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['I', 'love', 'machine', 'learning']\n",
            "['I', 'love', 'machine', 'learning']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0OJzfltsf4Be"
      },
      "source": [
        "Here our source (SRC - Input) is *french sequence* and target (TRG - Output) is *english sequence*. We also add 2 extra tokens \"start of sequence\" and \"end of sequence\" for effective model training."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ztK5PjShBN_M"
      },
      "source": [
        "SRC = Field(tokenize = tokenize_fr, \n",
        "            init_token = '<sos>', \n",
        "            eos_token = '<eos>', \n",
        "            lower = True)\n",
        "\n",
        "TRG = Field(tokenize = tokenize_en, \n",
        "            init_token = '<sos>', \n",
        "            eos_token = '<eos>', \n",
        "            lower = True)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UR61PPo7NJOo"
      },
      "source": [
        "fields=[('fr',SRC),('en',TRG)]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "83hU-jxyOy1X"
      },
      "source": [
        "example_train=[data.Example.fromlist([df_train.fr[i],df_train.en[i]],fields) for i in range (df_train.shape[0])]\n",
        "example_test=[data.Example.fromlist([df_test.fr[i],df_test.en[i]],fields) for i in range (df_test.shape[0])]\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OhJPe_uVYde2"
      },
      "source": [
        "Create dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6jEQDQMtP9Lx"
      },
      "source": [
        "train_data = data.Dataset(example_train, fields)\n",
        "test_data= data.Dataset(example_test,fields)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TkcjHbbuQP5V"
      },
      "source": [
        "\n",
        "Let's look at one of the examples in the training set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hN6IJggTCBH6",
        "outputId": "9fc9d5b1-52dd-46f0-c322-ebf83da22da0"
      },
      "source": [
        "print(vars(train_data.examples[0]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'fr': ['ce', 'sont', 'des', 'pas', '.'], 'en': ['it', \"'s\", 'footsteps', '.']}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p3ldo6shYhwP"
      },
      "source": [
        "Build vocabulary"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BY3qVJbpK_2L"
      },
      "source": [
        "MAX_VOCAB_SIZE=25_000\n",
        "SRC.build_vocab(train_data,min_freq=2,max_size=MAX_VOCAB_SIZE)\n",
        "TRG.build_vocab(train_data,min_freq=2,max_size=MAX_VOCAB_SIZE)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iy0xQVgdLBkm",
        "outputId": "cecac8a2-5453-4e89-f7e5-345960bc028c"
      },
      "source": [
        "print(f\"Unique tokens in source (fr) vocabulary: {len(SRC.vocab)}\")\n",
        "print(f\"Unique tokens in target (en) vocabulary: {len(TRG.vocab)}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Unique tokens in source (fr) vocabulary: 7652\n",
            "Unique tokens in target (en) vocabulary: 6915\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bFO73am_Yp7e"
      },
      "source": [
        "Define the device"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4I_59ly4LC4T"
      },
      "source": [
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jr-Rn1TrYsTZ"
      },
      "source": [
        "Create the iterators"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_0GNSQSCLEOB"
      },
      "source": [
        "BATCH_SIZE=32\n",
        "train_iterator, test_iterator = BucketIterator.splits(\n",
        "    (train_data,  test_data), \n",
        "    batch_size = BATCH_SIZE,sort_within_batch = True,\n",
        "    sort_key = lambda x: len(x.fr),\n",
        "    device = device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hPtdS37GjhX8"
      },
      "source": [
        "## **Building seq2seq Model**\n",
        "We'll be building our model in three parts. The encoder, the decoder and a seq2seq model that encapsulates the encoder and decoder and will provide a way to interface with each."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b6kktU14kk0i"
      },
      "source": [
        " #### Encoder Model \n",
        " First, the encoder, a 2 layer LSTM.\n",
        "\n",
        "For a multi-layer LSTM, the input sentence, $X$, after being embedded goes into the first (bottom) layer of the LSTM.Along with input sequence , LSTM take in hidden state and cell state from previous time step and return new hidden state and cell state at each time step.Initial hidden state and cell state will be initialized to tensor of all zeros.Only hidden state from the first layer is passed as input to the second layer, and not the cell state.We will also output a context vector per layer, $z^l$.Our context vector will be both the final hidden state and the final cell state, i.e. $z^l = (h_T^l, c_T^l)$.\n",
        "\n",
        "Thus, representing each layer with a superscript, the hidden states in each layer are given by:\n",
        "\n",
        "$$\\begin{align*}\n",
        "(h_t^1, c_t^1) = \\text{EncoderLSTM}^1(e(x_t), (h_{t-1}^1, c_{t-1}^1))\\\\\n",
        "(h_t^2, c_t^2) = \\text{EncoderLSTM}^2(h_t^1, (h_{t-1}^2, c_{t-1}^2))\n",
        "\\end{align*}$$\n",
        "\n",
        "\n",
        "\n",
        "We create this in code by making an Encoder module, which  inherit from `torch.nn.Module` and use the `super().__init__()` as some boilerplate code. The encoder takes the following arguments:\n",
        "\n",
        "\n",
        "*   `input_dim` is the size/dimensionality of the one-hot vectors that will be input to the encoder. This is equal to the input (source) vocabulary size.\n",
        "*   `emb_dim` is the dimensionality of the embedding layer. This layer converts the one-hot vectors into dense vectors with emb_dim dimensions.\n",
        "*  `hid_dim` is the dimensionality of the hidden and cell states.\n",
        "*   `n_layers` is the number of layers in the LSTM.\n",
        "\n",
        "*   `dropout` is the amount of dropout to use. This is a regularization parameter to prevent overfitting.\n",
        "\n",
        "\n",
        "In the `forward` method, we pass in the source sentence, $X$, which is converted into dense vectors using the embedding layer, and then dropout is applied. These embeddings are then passed into the LSTM. As we pass a whole sequence to the LSTM, it will automatically do the recurrent calculation of the hidden states over the whole sequence.We do not pass an initial hidden or cell state to the LSTM. This is because, if no hidden/cell state is passed to the LSTM, it will automatically create an initial hidden/cell state as a tensor of all zeros.\n",
        "\n",
        "The LSTM returns: outputs (the top-layer hidden state for each time-step), hidden (the final hidden state for each layer, $h_T$, stacked on top of each other) and cell (the final cell state for each layer, $c_T$, stacked on top of each other).\n",
        "\n",
        "As we only need the final hidden and cell states (to make our context vector), forward only returns hidden and cell.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lt5hSy0_OybI"
      },
      "source": [
        "class Encoder(nn.Module):\n",
        "    def __init__(self, input_dim, emb_dim, hid_dim, n_layers, dropout):\n",
        "        super().__init__()\n",
        "        \n",
        "        self.hid_dim = hid_dim\n",
        "        self.n_layers = n_layers\n",
        "        \n",
        "        self.embedding = nn.Embedding(input_dim, emb_dim)\n",
        "        \n",
        "        self.rnn = nn.LSTM(emb_dim, hid_dim, n_layers, dropout = dropout)\n",
        "        \n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        \n",
        "    def forward(self, src):\n",
        "        \n",
        "        #src = [src len, batch size]\n",
        "        \n",
        "        embedded = self.dropout(self.embedding(src))\n",
        "        \n",
        "        #embedded = [src len, batch size, emb dim]\n",
        "        \n",
        "        outputs, (hidden, cell) = self.rnn(embedded)\n",
        "        \n",
        "        #outputs = [src len, batch size, hid dim * n directions]\n",
        "        #hidden = [n layers * n directions, batch size, hid dim]\n",
        "        #cell = [n layers * n directions, batch size, hid dim]\n",
        "        \n",
        "        #outputs are always from the top hidden layer\n",
        "        \n",
        "        return hidden, cell\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j2EObTGNmNxH"
      },
      "source": [
        "#### Decoder  \n",
        "Next, we'll build our decoder, which will also be a 2-layer  LSTM.\n",
        "\n",
        "The Decoder class does a single step of decoding, i.e. it ouputs single token per time-step. The first layer will receive a hidden and cell state from the previous time-step, $(s_{t-1}^1, c_{t-1}^1)$, and feeds it through the LSTM with the current embedded token, $y_t$, to produce a new hidden and cell state, $(s_t^1, c_t^1)$. The subsequent layers will use the hidden state from the layer below, $s_t^{l-1}$, and the previous hidden and cell states from their layer, $(s_{t-1}^l, c_{t-1}^l)$. This provides equations very similar to those in the encoder.\n",
        "\n",
        "$$\\begin{align*}\n",
        "(s_t^1, c_t^1) = \\text{DecoderLSTM}^1(d(y_t), (s_{t-1}^1, c_{t-1}^1))\\\\\n",
        "(s_t^2, c_t^2) = \\text{DecoderLSTM}^2(s_t^1, (s_{t-1}^2, c_{t-1}^2))\n",
        "\\end{align*}$$\n",
        "Remember that the initial hidden and cell states to our decoder are our context vectors, which are the final hidden and cell states of our encoder from the same layer, i.e. $(s_0^l,c_0^l)=z^l=(h_T^l,c_T^l)$.\n",
        "\n",
        "We then pass the hidden state from the top layer of the RNN, $s_t^L$, through a linear layer, $f$, to make a prediction of what the next token in the target (output) sequence should be, $\\hat{y}_{t+1}$.\n",
        "\n",
        "$$\\hat{y}_{t+1} = f(s_t^L)$$\n",
        "The arguments and initialization are similar to the Encoder class, except we now have an output_dim which is the size of the vocabulary for the output/target. There is also the addition of the Linear layer, used to make the predictions from the top layer hidden state.\n",
        "\n",
        "Within the forward method, we accept a batch of input tokens, previous hidden states and previous cell states. As we are only decoding one token at a time, the input tokens will always have a sequence length of 1. We unsqueeze the input tokens to add a sentence length dimension of 1. Then, similar to the encoder, we pass through an embedding layer and apply dropout. This batch of embedded tokens is then passed into the RNN with the previous hidden and cell states. This produces an output (hidden state from the top layer of the RNN), a new hidden state (one for each layer, stacked on top of each other) and a new cell state (also one per layer, stacked on top of each other). We then pass the output (after getting rid of the sentence length dimension) through the linear layer to receive our prediction. We then return the prediction, the new hidden state and the new cell state."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cn9RWH9QbfOk"
      },
      "source": [
        "class Decoder(nn.Module):\n",
        "    def __init__(self, output_dim, emb_dim, hid_dim, n_layers, dropout):\n",
        "        super().__init__()\n",
        "        \n",
        "        self.output_dim = output_dim\n",
        "        self.hid_dim = hid_dim\n",
        "        self.n_layers = n_layers\n",
        "        \n",
        "        self.embedding = nn.Embedding(output_dim, emb_dim)\n",
        "        \n",
        "        self.rnn = nn.LSTM(emb_dim, hid_dim, n_layers, dropout = dropout)\n",
        "        \n",
        "        self.fc_out = nn.Linear(hid_dim, output_dim)\n",
        "        \n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        \n",
        "    def forward(self, input, hidden, cell):\n",
        "        \n",
        "        #input = [batch size]\n",
        "        #hidden = [n layers * n directions, batch size, hid dim]\n",
        "        #cell = [n layers * n directions, batch size, hid dim]\n",
        "        \n",
        "        #n directions in the decoder will both always be 1, therefore:\n",
        "        #hidden = [n layers, batch size, hid dim]\n",
        "        #context = [n layers, batch size, hid dim]\n",
        "        \n",
        "        input = input.unsqueeze(0)\n",
        "        \n",
        "        #input = [1, batch size]\n",
        "        \n",
        "        embedded = self.dropout(self.embedding(input))\n",
        "        \n",
        "        #embedded = [1, batch size, emb dim]\n",
        "                \n",
        "        output, (hidden, cell) = self.rnn(embedded, (hidden, cell))\n",
        "        \n",
        "        #output = [seq len, batch size, hid dim * n directions]\n",
        "        #hidden = [n layers * n directions, batch size, hid dim]\n",
        "        #cell = [n layers * n directions, batch size, hid dim]\n",
        "        \n",
        "        #seq len and n directions will always be 1 in the decoder, therefore:\n",
        "        #output = [1, batch size, hid dim]\n",
        "        #hidden = [n layers, batch size, hid dim]\n",
        "        #cell = [n layers, batch size, hid dim]\n",
        "        \n",
        "        prediction = self.fc_out(output.squeeze(0))\n",
        "        \n",
        "        #prediction = [batch size, output dim]\n",
        "        \n",
        "        return prediction, hidden, cell\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9onop7QXuyTb"
      },
      "source": [
        "#### Seq2Seq (Encoder + Decoder) \n",
        "For the final part of the implemenetation, we'll implement the `seq2seq` model. This will handle:\n",
        "\n",
        "*   receiving the input/source sentence\n",
        "*   using the encoder to produce the context vectors\n",
        "*   using the decoder to produce the predicted output/target sentence\n",
        "\n",
        "\n",
        "The `Seq2Seq` model takes in an `Encoder`, `Decoder`, and a `device` (used to place tensors on the GPU, if it exists).\n",
        "\n",
        "Our `forward` method takes the source sentence, target sentence and a `teacher-forcing ratio`. The `teacher forcing ratio` is used when training our model. When decoding, at each time-step we will predict what the next token in the target sequence will be from the previous tokens decoded, $\\hat{y}_{t+1}=f(s_t^L)$. With probability equal to the teaching forcing ratio (`teacher_forcing_ratio`) we will use the actual ground-truth next token in the sequence as the input to the decoder during the next time-step. However, with probability 1 - `teacher_forcing_ratio`, we will use the token that the model predicted as the next input to the model, even if it doesn't match the actual next token in the sequence.\n",
        "\n",
        "The first thing we do in the forward method is to create an outputs tensor that will store all of our predictions, $\\hat{Y}$.\n",
        "\n",
        "We then feed the input/source sentence, `src`, into the encoder and receive out final hidden and cell states.\n",
        "\n",
        "The first input to the decoder is the start of sequence (`<sos>`) token. As our trg tensor already has the `<sos>` token appended we get our $y_1$ by slicing into it. We know how long our target sentences should be (max_len), so we loop that many times. The last token input into the decoder is the one before the `<eos>` token - the <eos> token is never input into the decoder.\n",
        "\n",
        "During each iteration of the loop, we:\n",
        "\n",
        "\n",
        "\n",
        "*   pass the input, previous hidden and previous cell states ($y_t, s_{t-1}, c_{t-1}$) into the decoder\n",
        "*   receive a prediction, next hidden state and next cell state ($\\hat{y}_{t+1}, s_{t}, c_{t}$) from the decoder\n",
        "*   place our prediction, $\\hat{y}_{t+1}$/output in our tensor of predictions, $\\hat{Y}$/outputs\n",
        "*  decide if we are going to \"teacher force\" or not\n",
        "  *  if we do, the next input is the ground-truth next token in the sequence, $y_{t+1}$/trg[t]\n",
        "  *   if we don't, the next input is the predicted next token in the sequence, $\\hat{y}_{t+1}$/top1, which we get by doing an argmax over the output tensor\n",
        "\n",
        "Once we've made all of our predictions, we return our tensor full of predictions, $\\hat{Y}$/outputs.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xN_6XiVBlJfV"
      },
      "source": [
        "class Seq2Seq(nn.Module):\n",
        "    def __init__(self, encoder, decoder, device):\n",
        "        super().__init__()\n",
        "        \n",
        "        self.encoder = encoder\n",
        "        self.decoder = decoder\n",
        "        self.device = device\n",
        "        \n",
        "        assert encoder.hid_dim == decoder.hid_dim, \\\n",
        "            \"Hidden dimensions of encoder and decoder must be equal!\"\n",
        "        assert encoder.n_layers == decoder.n_layers, \\\n",
        "            \"Encoder and decoder must have equal number of layers!\"\n",
        "        \n",
        "    def forward(self, src, trg, teacher_forcing_ratio = 0.5):\n",
        "        \n",
        "        #src = [src len, batch size]\n",
        "        #trg = [trg len, batch size]\n",
        "        #teacher_forcing_ratio is probability to use teacher forcing\n",
        "        #e.g. if teacher_forcing_ratio is 0.75 we use ground-truth inputs 75% of the time\n",
        "        \n",
        "        batch_size = trg.shape[1]\n",
        "        trg_len = trg.shape[0]\n",
        "        trg_vocab_size = self.decoder.output_dim\n",
        "        \n",
        "        #tensor to store decoder outputs\n",
        "        outputs = torch.zeros(trg_len, batch_size, trg_vocab_size).to(self.device)\n",
        "        \n",
        "        #last hidden state of the encoder is used as the initial hidden state of the decoder\n",
        "        hidden, cell = self.encoder(src)\n",
        "        \n",
        "        #first input to the decoder is the <sos> tokens\n",
        "        input = trg[0,:]\n",
        "        \n",
        "        for t in range(1, trg_len):\n",
        "            \n",
        "            #insert input token embedding, previous hidden and previous cell states\n",
        "            #receive output tensor (predictions) and new hidden and cell states\n",
        "            output, hidden, cell = self.decoder(input, hidden, cell)\n",
        "            \n",
        "            #place predictions in a tensor holding predictions for each token\n",
        "            outputs[t] = output\n",
        "            \n",
        "            #decide if we are going to use teacher forcing or not\n",
        "            teacher_force = random.random() < teacher_forcing_ratio\n",
        "            \n",
        "            #get the highest predicted token from our predictions\n",
        "            top1 = output.argmax(1) \n",
        "            \n",
        "            #if teacher forcing, use actual next token as next input\n",
        "            #if not, use predicted token\n",
        "            input = trg[t] if teacher_force else top1\n",
        "        \n",
        "        return outputs\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2kAi92iKP6U-"
      },
      "source": [
        "##  **Training Model**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QrRQeVSRQfjn"
      },
      "source": [
        "We  define the encoder, decoder and then our Seq2Seq model, which we place on the device."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cSX4cvf5xJVM"
      },
      "source": [
        "INPUT_DIM = len(SRC.vocab)\n",
        "OUTPUT_DIM = len(TRG.vocab)\n",
        "ENC_EMB_DIM = 256\n",
        "DEC_EMB_DIM = 256\n",
        "HID_DIM = 512\n",
        "N_LAYERS = 2\n",
        "ENC_DROPOUT = 0.2\n",
        "DEC_DROPOUT = 0.2\n",
        "\n",
        "enc = Encoder(INPUT_DIM, ENC_EMB_DIM, HID_DIM, N_LAYERS, ENC_DROPOUT)\n",
        "dec = Decoder(OUTPUT_DIM, DEC_EMB_DIM, HID_DIM, N_LAYERS, DEC_DROPOUT)\n",
        "\n",
        "model = Seq2Seq(enc, dec, device).to(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9G5mIf-xLshk"
      },
      "source": [
        "Next up is initializing the weights of our model.We initialize all weights from a uniform distribution between -0.08 and +0.08.We initialize weights in PyTorch by creating a function which we apply to our model. When using apply, the init_weights function will be called on every module and sub-module within our model. For each module we loop through all of the parameters and sample them from a uniform distribution with `nn.init.uniform_`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TBhX5dKuLNar",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "25ffb1c5-9905-4057-d637-7cc9774245e9"
      },
      "source": [
        "def init_weights(m):\n",
        "    for name, param in m.named_parameters():\n",
        "        nn.init.uniform_(param.data, -0.08, 0.08)\n",
        "        \n",
        "model.apply(init_weights)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Seq2Seq(\n",
              "  (encoder): Encoder(\n",
              "    (embedding): Embedding(7652, 256)\n",
              "    (rnn): LSTM(256, 512, num_layers=2, dropout=0.2)\n",
              "    (dropout): Dropout(p=0.2, inplace=False)\n",
              "  )\n",
              "  (decoder): Decoder(\n",
              "    (embedding): Embedding(6915, 256)\n",
              "    (rnn): LSTM(256, 512, num_layers=2, dropout=0.2)\n",
              "    (fc_out): Linear(in_features=512, out_features=6915, bias=True)\n",
              "    (dropout): Dropout(p=0.2, inplace=False)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 229
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BgOsUTvCMDT9"
      },
      "source": [
        "We also define a function that will calculate the number of trainable parameters in the model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PSdevJJNLPOt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "889db574-30ba-401c-be9d-153c755db54a"
      },
      "source": [
        "def count_parameters(model):\n",
        "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "\n",
        "print(f'The model has {count_parameters(model):,} trainable parameters')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The model has 14,632,963 trainable parameters\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jKaDwGo0MIhM"
      },
      "source": [
        "\n",
        "We define our optimizer, which we use to update our parameters in the training loop. Here, we'll use Adam."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A-CvhZwYLQoT"
      },
      "source": [
        "optimizer = optim.Adam(model.parameters(),lr=1e-4)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4qOPtFnJMS0l"
      },
      "source": [
        "Next, we define our loss function as `CrossEntropyLoss` function \n",
        "\n",
        "Our loss function calculates the average loss per token, however by passing the index of the <pad> token as the `ignore_index` argument we ignore the loss whenever the target token is a padding token."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kO11j3WELR5P",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "34c9ea68-c853-4bfd-bebf-729662e308cb"
      },
      "source": [
        "TRG_PAD_IDX = TRG.vocab.stoi[TRG.pad_token]\n",
        "\n",
        "criterion = nn.CrossEntropyLoss(ignore_index = TRG_PAD_IDX)\n",
        "TRG_PAD_IDX"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 232
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t-cNUX0bMq7a"
      },
      "source": [
        "Next, we'll define our training loop.\n",
        "\n",
        "First, we'll set the model into \"training mode\" with model and then iterate through our data iterator.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q-HReR1sLS8w"
      },
      "source": [
        "def train(model, iterator, optimizer, criterion, clip):\n",
        "    \n",
        "    model.train()\n",
        "    \n",
        "    epoch_loss = 0\n",
        "    \n",
        "    for i, batch in enumerate(iterator):\n",
        "        #get the source and target sentences from the batch\n",
        "        fr = batch.fr\n",
        "        en = batch.en\n",
        "        \n",
        "        optimizer.zero_grad()#zero the gradients calculated from the last batch\n",
        "        \n",
        "        output = model(fr, en)#feed the source and target into the model to get the output\n",
        "        \n",
        "        #en = [sentence len, batch size]\n",
        "        #output = [sentence len, batch size, output dim]\n",
        "        \n",
        "        output_dim = output.shape[-1]\n",
        "        \n",
        "        \n",
        "        output = output[1:].view(-1, output_dim)#as the loss function only works on 2d inputs with 1d targets flatten each of them\n",
        "        en = en[1:].view(-1)\n",
        "        \n",
        "        #en = [(en - 1) * batch size]\n",
        "        #output = [(en len - 1) * batch size, output dim]\n",
        "        \n",
        "        loss = criterion(output, en)\n",
        "        \n",
        "        loss.backward()#calculate the gradients\n",
        "        \n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), clip)#clip the gradients to prevent them from exploding \n",
        "        \n",
        "        optimizer.step()# update the parameters \n",
        "        \n",
        "        epoch_loss += loss.item()#sum the loss value to a running total\n",
        "        \n",
        "    return epoch_loss / len(iterator)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oRi50YVdPaQP"
      },
      "source": [
        "Next, we'll define our evaluation loop.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jfm7iiOmLUhv"
      },
      "source": [
        "def evaluate(model, iterator, criterion):\n",
        "    \n",
        "    model.eval()\n",
        "    \n",
        "    epoch_loss = 0\n",
        "    \n",
        "    with torch.no_grad():\n",
        "    \n",
        "        for i, batch in enumerate(iterator):\n",
        "\n",
        "            fr = batch.fr\n",
        "            en = batch.en\n",
        "\n",
        "            output = model(fr, en, 0) #turn off teacher forcing\n",
        "\n",
        "\n",
        "            output_dim = output.shape[-1]\n",
        "            \n",
        "            output = output[1:].view(-1, output_dim)\n",
        "            en = en[1:].view(-1)\n",
        "\n",
        "\n",
        "\n",
        "            loss = criterion(output, en)\n",
        "            \n",
        "            epoch_loss += loss.item()\n",
        "        \n",
        "    return epoch_loss / len(iterator)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SJctB0p3bVSe"
      },
      "source": [
        "\n",
        "Next, we'll create a function that we'll use to tell us how long an epoch takes."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mXrLres2LWHg"
      },
      "source": [
        "def epoch_time(start_time, end_time):\n",
        "    elapsed_time = end_time - start_time\n",
        "    elapsed_mins = int(elapsed_time / 60)\n",
        "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
        "    return elapsed_mins, elapsed_secs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bvw4HcNrbevz"
      },
      "source": [
        "We can finally start training our model!\n",
        "\n",
        "At each epoch, we'll be checking if our model has achieved the best validation loss so far. If it has, we'll update our best validation loss and save the parameters of our model . Then, when we come to test our model, we'll use the saved parameters used to achieve the best validation loss.\n",
        "\n",
        "We'll be printing out both the loss and the perplexity at each epoch. It is easier to see a change in perplexity than a change in loss as the numbers are much bigger."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HGdzElxhLXKm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0ba31856-60fc-4fca-ac23-0999323f36dc"
      },
      "source": [
        "N_EPOCHS = 30\n",
        "CLIP = 1\n",
        "train_los=[]\n",
        "test_los=[]\n",
        "best_test_loss = float('inf')\n",
        "\n",
        "for epoch in range(N_EPOCHS):\n",
        "    \n",
        "    start_time = time.time()\n",
        "    \n",
        "    train_loss = train(model, train_iterator, optimizer, criterion, CLIP)\n",
        "    train_los.append(train_loss)\n",
        "    test_loss = evaluate(model, test_iterator, criterion)\n",
        "    test_los.append(test_loss)\n",
        "    \n",
        "    end_time = time.time()\n",
        "    \n",
        "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
        "    \n",
        "    if test_loss < best_test_loss:\n",
        "        best_test_loss = test_loss\n",
        "        torch.save(model.state_dict(), 'saved-model.pt')\n",
        "    \n",
        "    print(f'Epoch: {epoch+1:02} | Time: {epoch_mins}m {epoch_secs}s')\n",
        "    print(f'\\tTrain Loss: {train_loss:.3f} | Train PPL: {math.exp(train_loss):7.3f}')\n",
        "    print(f'\\t Test. Loss: {test_loss:.3f} |  Test. PPL: {math.exp(test_loss):7.3f}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 01 | Time: 0m 40s\n",
            "\tTrain Loss: 5.172 | Train PPL: 176.306\n",
            "\t Test. Loss: 4.715 |  Test. PPL: 111.560\n",
            "Epoch: 02 | Time: 0m 40s\n",
            "\tTrain Loss: 4.607 | Train PPL: 100.219\n",
            "\t Test. Loss: 4.468 |  Test. PPL:  87.151\n",
            "Epoch: 03 | Time: 0m 40s\n",
            "\tTrain Loss: 4.382 | Train PPL:  80.000\n",
            "\t Test. Loss: 4.342 |  Test. PPL:  76.825\n",
            "Epoch: 04 | Time: 0m 40s\n",
            "\tTrain Loss: 4.237 | Train PPL:  69.221\n",
            "\t Test. Loss: 4.295 |  Test. PPL:  73.332\n",
            "Epoch: 05 | Time: 0m 40s\n",
            "\tTrain Loss: 4.134 | Train PPL:  62.418\n",
            "\t Test. Loss: 4.235 |  Test. PPL:  69.070\n",
            "Epoch: 06 | Time: 0m 40s\n",
            "\tTrain Loss: 4.040 | Train PPL:  56.831\n",
            "\t Test. Loss: 4.196 |  Test. PPL:  66.418\n",
            "Epoch: 07 | Time: 0m 40s\n",
            "\tTrain Loss: 3.951 | Train PPL:  51.966\n",
            "\t Test. Loss: 4.160 |  Test. PPL:  64.071\n",
            "Epoch: 08 | Time: 0m 40s\n",
            "\tTrain Loss: 3.869 | Train PPL:  47.909\n",
            "\t Test. Loss: 4.136 |  Test. PPL:  62.577\n",
            "Epoch: 09 | Time: 0m 40s\n",
            "\tTrain Loss: 3.800 | Train PPL:  44.691\n",
            "\t Test. Loss: 4.120 |  Test. PPL:  61.581\n",
            "Epoch: 10 | Time: 0m 40s\n",
            "\tTrain Loss: 3.723 | Train PPL:  41.407\n",
            "\t Test. Loss: 4.100 |  Test. PPL:  60.342\n",
            "Epoch: 11 | Time: 0m 40s\n",
            "\tTrain Loss: 3.663 | Train PPL:  38.971\n",
            "\t Test. Loss: 4.060 |  Test. PPL:  57.948\n",
            "Epoch: 12 | Time: 0m 40s\n",
            "\tTrain Loss: 3.589 | Train PPL:  36.181\n",
            "\t Test. Loss: 4.058 |  Test. PPL:  57.862\n",
            "Epoch: 13 | Time: 0m 40s\n",
            "\tTrain Loss: 3.528 | Train PPL:  34.059\n",
            "\t Test. Loss: 4.050 |  Test. PPL:  57.394\n",
            "Epoch: 14 | Time: 0m 40s\n",
            "\tTrain Loss: 3.472 | Train PPL:  32.202\n",
            "\t Test. Loss: 4.034 |  Test. PPL:  56.508\n",
            "Epoch: 15 | Time: 0m 40s\n",
            "\tTrain Loss: 3.413 | Train PPL:  30.347\n",
            "\t Test. Loss: 4.025 |  Test. PPL:  55.976\n",
            "Epoch: 16 | Time: 0m 40s\n",
            "\tTrain Loss: 3.359 | Train PPL:  28.760\n",
            "\t Test. Loss: 4.016 |  Test. PPL:  55.492\n",
            "Epoch: 17 | Time: 0m 40s\n",
            "\tTrain Loss: 3.303 | Train PPL:  27.194\n",
            "\t Test. Loss: 4.007 |  Test. PPL:  54.978\n",
            "Epoch: 18 | Time: 0m 40s\n",
            "\tTrain Loss: 3.253 | Train PPL:  25.861\n",
            "\t Test. Loss: 4.011 |  Test. PPL:  55.218\n",
            "Epoch: 19 | Time: 0m 40s\n",
            "\tTrain Loss: 3.198 | Train PPL:  24.480\n",
            "\t Test. Loss: 4.001 |  Test. PPL:  54.656\n",
            "Epoch: 20 | Time: 0m 40s\n",
            "\tTrain Loss: 3.143 | Train PPL:  23.173\n",
            "\t Test. Loss: 4.004 |  Test. PPL:  54.829\n",
            "Epoch: 21 | Time: 0m 40s\n",
            "\tTrain Loss: 3.093 | Train PPL:  22.045\n",
            "\t Test. Loss: 3.990 |  Test. PPL:  54.077\n",
            "Epoch: 22 | Time: 0m 40s\n",
            "\tTrain Loss: 3.054 | Train PPL:  21.206\n",
            "\t Test. Loss: 3.990 |  Test. PPL:  54.055\n",
            "Epoch: 23 | Time: 0m 40s\n",
            "\tTrain Loss: 2.994 | Train PPL:  19.956\n",
            "\t Test. Loss: 4.001 |  Test. PPL:  54.676\n",
            "Epoch: 24 | Time: 0m 40s\n",
            "\tTrain Loss: 2.953 | Train PPL:  19.155\n",
            "\t Test. Loss: 3.994 |  Test. PPL:  54.246\n",
            "Epoch: 25 | Time: 0m 40s\n",
            "\tTrain Loss: 2.904 | Train PPL:  18.254\n",
            "\t Test. Loss: 4.005 |  Test. PPL:  54.845\n",
            "Epoch: 26 | Time: 0m 40s\n",
            "\tTrain Loss: 2.851 | Train PPL:  17.298\n",
            "\t Test. Loss: 4.020 |  Test. PPL:  55.719\n",
            "Epoch: 27 | Time: 0m 40s\n",
            "\tTrain Loss: 2.812 | Train PPL:  16.638\n",
            "\t Test. Loss: 4.016 |  Test. PPL:  55.469\n",
            "Epoch: 28 | Time: 0m 40s\n",
            "\tTrain Loss: 2.761 | Train PPL:  15.820\n",
            "\t Test. Loss: 4.023 |  Test. PPL:  55.860\n",
            "Epoch: 29 | Time: 0m 40s\n",
            "\tTrain Loss: 2.726 | Train PPL:  15.271\n",
            "\t Test. Loss: 4.026 |  Test. PPL:  56.040\n",
            "Epoch: 30 | Time: 0m 40s\n",
            "\tTrain Loss: 2.677 | Train PPL:  14.539\n",
            "\t Test. Loss: 4.031 |  Test. PPL:  56.317\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FR-wtcQMvRpj"
      },
      "source": [
        "Let's view train and test loss of our model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bjUCB1yYMfIa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 277
        },
        "outputId": "5d06ef2f-9d7c-430d-c7b8-e8fe361e1459"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.style.use('seaborn-darkgrid')\n",
        "plt.figure()\n",
        "plt.plot(train_los, color = 'magenta')\n",
        "plt.plot(test_los, color = '#606060')\n",
        "plt.title('Train and test Loss')\n",
        "plt.legend(['train_loss', 'test_loss'], loc = 'upper right')\n",
        "plt.grid(axis = 'y', c = 'black', alpha = 0.2)\n",
        "plt.grid(axis = 'x', c = 'black', alpha = 0.2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X_oFL7fGcfIV"
      },
      "source": [
        "## **Inference**\n",
        "\n",
        "\n",
        "Now, we'll grab some answers to questions from our dataset and see how well our model did."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BkLA6tw1v0n3"
      },
      "source": [
        "def predict_duplicate(sentence, src_field, trg_field, model, device, max_len = 50):\n",
        "\n",
        "    model.eval()\n",
        "        \n",
        "    if isinstance(sentence, str):\n",
        "        nlp = spacy.load('fr_core_news_sm')\n",
        "        #('en_core_web_sm')\n",
        "        tokens = [token.text.lower() for token in nlp(sentence)]\n",
        "    else:\n",
        "        tokens = [token.lower() for token in sentence]\n",
        "\n",
        "    tokens = [src_field.init_token] + tokens + [src_field.eos_token]\n",
        "        \n",
        "    src_indexes = [src_field.vocab.stoi[token] for token in tokens]\n",
        "    \n",
        "    src_tensor = torch.LongTensor(src_indexes).unsqueeze(1).to(device)\n",
        "\n",
        "    # src_len = torch.LongTensor([len(src_indexes)])\n",
        "    \n",
        "    with torch.no_grad():\n",
        "        hidden,cell = model.encoder(src_tensor)\n",
        "\n",
        "        \n",
        "    trg_indexes = [trg_field.vocab.stoi[trg_field.init_token]]\n",
        "\n",
        "    # attentions = torch.zeros(max_len, 1, len(src_indexes)).to(device)\n",
        "    \n",
        "    for i in range(max_len):\n",
        "\n",
        "        trg_tensor = torch.LongTensor([trg_indexes[-1]]).to(device)\n",
        "                \n",
        "        with torch.no_grad():\n",
        "            output, hidden, cell = model.decoder(trg_tensor, hidden, cell)\n",
        "            # output, hidden, cell = model.decoder(trg_tensor, hidden, cell)\n",
        "\n",
        "            \n",
        "        pred_token = output.argmax(1).item()\n",
        "        \n",
        "        trg_indexes.append(pred_token)\n",
        "\n",
        "        if pred_token == trg_field.vocab.stoi[trg_field.eos_token]:\n",
        "            break\n",
        "    \n",
        "    trg_tokens = [trg_field.vocab.itos[i] for i in trg_indexes]\n",
        "    \n",
        "    return trg_tokens[1:]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-QgbTTt9xuo5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aa6873f5-8f80-4c6c-8e4e-877b72690966"
      },
      "source": [
        "example_idx = 39\n",
        "\n",
        "src = vars(train_data.examples[example_idx])['fr']\n",
        "trg = vars(train_data.examples[example_idx])['en']\n",
        "\n",
        "print(f'src = {src}')\n",
        "print(f'trg = {trg}')\n",
        "translate_sentence= predict_duplicate(src, SRC, TRG, model, device)\n",
        "\n",
        "print(f'predicted trg = {translate_sentence}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "src = ['entre', '.']\n",
            "trg = ['come', 'in', '.']\n",
            "predicted trg = ['come', 'in', '.', '<eos>']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GiHtnbd5vdnS"
      },
      "source": [
        "Let's predict some answers from test set too"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UJymnxumgROy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "331ffa83-bc80-49f4-d27f-bbe5e475ba66"
      },
      "source": [
        "example_idx = 15\n",
        "\n",
        "src = vars(test_data.examples[example_idx])['fr']\n",
        "trg = vars(test_data.examples[example_idx])['en']\n",
        "\n",
        "print(f'src = {src}')\n",
        "print(f'trg = {trg}')\n",
        "translate_sentence= predict_duplicate(src, SRC, TRG, model, device)\n",
        "\n",
        "print(f'predicted trg = {translate_sentence}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "src = ['qui', 'êtes', '-', 'vous', '?']\n",
            "trg = ['what', 'are', 'you', 'doing', 'here', '?']\n",
            "predicted trg = ['who', 'are', 'you', '?', '<eos>']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_L7Yl_GTvgke",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4f4a6b85-3834-426e-d9a2-a65731b0a181"
      },
      "source": [
        "example_idx =85\n",
        "\n",
        "src = vars(test_data.examples[example_idx])['fr']\n",
        "trg = vars(test_data.examples[example_idx])['en']\n",
        "\n",
        "print(f'src = {src}')\n",
        "print(f'trg = {trg}')\n",
        "translate_sentence= predict_duplicate(src, SRC, TRG, model, device)\n",
        "\n",
        "print(f'predicted trg = {translate_sentence}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "src = ['sommaire']\n",
            "trg = ['contents']\n",
            "predicted trg = ['contents', '<eos>']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vq-UJnesLv9R",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "20a3c6af-b559-419e-fc27-cd2396f7aa3f"
      },
      "source": [
        "example_idx =86\n",
        "\n",
        "src = vars(test_data.examples[example_idx])['fr']\n",
        "trg = vars(test_data.examples[example_idx])['en']\n",
        "\n",
        "print(f'src = {src}')\n",
        "print(f'trg = {trg}')\n",
        "translate_sentence= predict_duplicate(src, SRC, TRG, model, device)\n",
        "\n",
        "print(f'predicted trg = {translate_sentence}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "src = ['tu', 'reviens', 'quand', 'à', \"l'\", 'école', '?']\n",
            "trg = ['when', 'are', 'you', 'coming', 'back', 'to', 'the', 'kindergarten', '?']\n",
            "predicted trg = ['you', 'you', 'gon', 'na', 'be', 'back', '?', '<eos>']\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}